{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering: \"Search by Face Expression\"\n",
    "\n",
    "Let's say you wanted to look up GIFs with the same facial expression as the one you're making. But you don't know how to describe in that expression in words/symbols. This challenge is similar to Google's \"search by image\" feature.\n",
    "\n",
    "In this exercise, you'll learn about **clustering**. Remember how we previously plotted songs onto an axis? We can go even further and automatically create clusters or groups of similar pieces of data. \n",
    "\n",
    "One way to solve this problem is with the following steps:\n",
    "\n",
    "- Step 1: Cluster the images into groups\n",
    "- Step 2: Consider your \"search\" face and see to which cluster it's closest \n",
    "- Step 3: Show the cluster's images to the user\n",
    "\n",
    "We'll do an example here where we cluster facial expressions. \n",
    "\n",
    "Let's start by taking this dataset, called the CK+ (Cohn Kanade) dataset. The images look as below:\n",
    "\n",
    "| S078_005_00000013 | S088_004_00000011 | S094_004_00000012 | S098_004_00000012 | S112_001_00000020 |\n",
    "| --- | --- | --- | --- | --- |\n",
    "|  <img width=\"120px\" src=\"img/S078_005_00000013.png\"/> |  <img width=\"120px\" src=\"img/S088_004_00000011.png\"/>  | <img width=\"120px\" src=\"img/S094_004_00000012.png\"/>  |  <img width=\"120px\" src=\"img/S098_004_00000012.png\"/> | <img width=\"120px\" src=\"img/S112_001_00000020.png\"/>  |\n",
    "\n",
    "By the way, we say that **clustering** is an **unsupervised** machine learning technique; in other words, we don't need labels. Just the data! Imagine how we learn concepts before learning language.\n",
    "\n",
    "\n",
    "## Features\n",
    "\n",
    "As usual in classic machine learning, we need to extract relevant *features* on our data to work with it. Good *features* represent the raw data in a concise and relevant way.\n",
    "\n",
    "One way that researchers have found to represent facial expressions is to use [Action Units (AU's)](https://en.wikipedia.org/wiki/Facial_Action_Coding_System \"Action Units\"). These are things like \"nose wrinkler\" or \"lip pucker\" or \"inner brow raiser\". These are values from 0 (minimal intensity) to 1 (maximal intensity).\n",
    "\n",
    "**Example**\n",
    "The following features corresponds to the image below. \n",
    "Note: the feature extraction step, converting from image to this feature data, is outside the scope of today's workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img align=\"right\" width=\"200px\" src=\"img/S112_001_00000020.png\"> \n",
    "-    AU1 - Inner brow raiser\n",
    "-    AU2 - Outer brow raiser\n",
    "-    AU5b - Upper lid raiser (slight)\n",
    "-    AU17 - Chin raiser\n",
    "-    AU22 - Lip funneler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, this one is:\n",
    "\n",
    "<img align=\"right\" width=\"200px\" src=\"img/S094_004_00000012.png\">\n",
    "- AU6 - Cheek raiser\n",
    "- AU12 - Lip corner puller\n",
    "- AU25 - Lips part\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "And this one:\n",
    "\n",
    "<img align=\"right\" width=\"200px\" src=\"img/S158_002_00000011.png\">\n",
    "- AU12 - Lip corner puller\n",
    "- AU14 - Dimpler\n",
    "- AU17 - Chin raiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll get back to the Similar Images problem in a bit. For now let's learn the K-Means Clustering algorithm, using an example from before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to group similar expressions using K-Means Clustering\n",
    "\n",
    "K-Means is a clustering algorithm. It's called K-Means because it tries to make K clusters by calculating means. \n",
    "\n",
    "Let's start with a simple example with only 2 features, the music dataset with tempo and acousticness.\n",
    "\n",
    "## Load and pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Import the data\n",
    "raw_data = pandas.read_csv('data/spotify.csv')  # Top 2017 songs of 2017 from kaggle.com\n",
    "dataset = pandas.DataFrame(raw_data, columns = ['tempo', 'acousticness', 'song_title', 'artist'])\n",
    "dataset = dataset[:20]  # Let's just get the top 20 songs\n",
    "\n",
    "# Perform Normalization [0,1]\n",
    "tempo_column = dataset[['tempo']].values.astype(float)\n",
    "tempo_scaler = MinMaxScaler().fit(tempo_column)\n",
    "tempo_scaled = tempo_scaler.transform(tempo_column)\n",
    "dataset['tempo_normalized'] = pandas.DataFrame(tempo_scaled)\n",
    "\n",
    "acoustic_column = dataset[['acousticness']].values.astype(float)\n",
    "acoustic_scaler = MinMaxScaler().fit(acoustic_column)\n",
    "acousticness_scaled = acoustic_scaler.transform(acoustic_column)\n",
    "dataset['acoustic_normalized'] = pandas.DataFrame(acousticness_scaled)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform K-Means Clustering on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert DataFrame to matrix\n",
    "features = pandas.DataFrame(dataset, columns = ['tempo_normalized', 'acoustic_normalized'])\n",
    "mat = features.values\n",
    "\n",
    "# Use sklearn\n",
    "km = KMeans(n_clusters=3)\n",
    "km.fit(mat)\n",
    "\n",
    "# Get cluster assignment labels\n",
    "dataset['cluster'] = km.labels_\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's visualize that by plotting all the original data points\n",
    "plot.rcParams[\"figure.figsize\"] = 10,10\n",
    "\n",
    "plot.scatter(features['tempo_normalized'], features['acoustic_normalized'], c=km.labels_)\n",
    "plot.xlabel('Tempo')\n",
    "plot.ylabel('Acousticness')\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    plot.annotate(row['song_title'], xy=(row['tempo_normalized'], row['acoustic_normalized']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's do some clustering on our face dataset\n",
    "\n",
    "If you want to also see the images from the CK dataset, you can download them from here (password provided in class):\n",
    "https://drive.google.com/file/d/1Jgf7IF56YjAXmjH7-hSPFikWjKt0EsOY/view?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Example:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<img width=\"120px\" src=\"ck_images/S037_003_00000022.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some code to show Markdown and images in a notebook\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "def printmd(arg):\n",
    "    display(Markdown(arg))\n",
    "def html_img(ipath, widthpx=120):\n",
    "    return '<img width=\"{}px\" src=\"{}\"/>'.format(widthpx, ipath)\n",
    "def show_image(ipath, widthpx=120):\n",
    "    printmd(html_img(ipath, widthpx))\n",
    "    \n",
    "#printmd(\"Example:\")\n",
    "#show_image(\"ck_images/\"+\"S037_003_00000022.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Possible approach**\n",
    "To get started, maybe copy the code from the example above and adjust it for the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later, also show some of the images in the clusters your model produces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
